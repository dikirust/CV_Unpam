<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Laporan CNN Klasifikasi Sampah</title>
    <style>
        body { font-family: Calibri, Arial, sans-serif; margin: 20px; line-height: 1.6; color: #000; }
        .container { max-width: 900px; margin: 0 auto; }
        h1, h2, h3 { color: #000; margin-top: 20px; }
        h1 { font-size: 22px; }
        h2 { font-size: 16px; margin-top: 25px; }
        h3 { font-size: 14px; }
        p { margin: 10px 0; text-align: justify; }
        ul, ol { margin: 10px 0 10px 30px; }
        li { margin: 5px 0; }
        table { border-collapse: collapse; width: 100%; margin: 15px 0; }
        th, td { border: 1px solid #000; padding: 10px; text-align: left; }
        th { background-color: #fff; font-weight: bold; }
        img { max-width: 100%; height: auto; margin: 20px 0; }
    </style>
</head>
<body>
<div class="container">

<h1>LAPORAN PROYEK CNN UNTUK KLASIFIKASI SAMPAH OTOMATIS</h1>
<p>Tanggal: 29 October 2025 | Program: Computer Vision & Deep Learning</p>

<h2>ABSTRAK</h2>
<p>Laporan ini menyajikan hasil pengembangan model Convolutional Neural Network (CNN) untuk klasifikasi otomatis lima kategori sampah: makanan organik (foodwaste), kaca (glass), logam (metal), kertas (paper), dan plastik (plastic). Model dilatih menggunakan dataset dengan lebih dari 4,116 gambar sampah training dan 2,520 gambar validation, serta dievaluasi pada 1,186 gambar test. Hasil menunjukkan model mencapai akurasi test sebesar <b>90.93%</b> dengan F1-score <b>0.9092</b>. Model ini menggunakan arsitektur CNN yang dioptimalkan untuk balance antara akurasi dan efisiensi komputasi, dengan total parameter sebanyak 473,477. Laporan komprehensif ini mencakup: latar belakang masalah, metodologi penelitian, arsitektur model lengkap, hasil eksperimen, analisis mendalam, pembahasan, rekomendasi implementasi, dan panduan deployment sistem.</p>

<h2>1. PENDAHULUAN</h2>

<h3>1.1 Latar Belakang dan Motivasi</h3>
<p>Permasalahan lingkungan global semakin meningkat seiring dengan pertumbuhan populasi dan konsumsi manusia. Salah satu isu kritis adalah pengelolaan sampah yang tidak terkelola dengan baik. Menurut data global, lebih dari 2 miliar ton sampah dihasilkan setiap tahun, namun hanya sekitar 5-10% yang didaur ulang dengan optimal. Indonesia sendiri menghasilkan lebih dari 60 juta ton sampah per tahun, dengan tingkat daur ulang yang masih kurang dari 15%.</p>

<p>Pemisahan sampah adalah langkah pertama dan paling penting dalam proses daur ulang. Namun, pemisahan manual memerlukan tenaga kerja besar, memakan waktu, dan sering kali tidak akurat. Investasi untuk tenaga kerja pemisahan sampah sangat tinggi, terutama di negara berkembang. Selain itu, pekerjaan ini berpotensi membahayakan kesehatan pekerja karena kontak langsung dengan sampah yang mengandung zat berbahaya.</p>

<p>Teknologi otomasi berbasis Artificial Intelligence (AI) dan Computer Vision dapat menjadi solusi efektif untuk meningkatkan efisiensi dan akurasi pemisahan sampah. Convolutional Neural Network (CNN) adalah salah satu arsitektur deep learning yang paling sukses dalam menyelesaikan masalah klasifikasi citra. CNN telah terbukti mampu mengenali pola visual kompleks dengan akurasi tinggi dalam berbagai aplikasi, dari deteksi objek, pengenalan wajah, hingga analisis medis.</p>

<h3>1.2 Rumusan Masalah</h3>
<p>Tantangan utama dalam proyek ini adalah:</p>
<ul>
<li>Bagaimana membangun model CNN yang dapat mengklasifikasikan sampah dengan akurasi tinggi?</li>
<li>Bagaimana mengoptimalkan performa model dengan keterbatasan komputasi hardware menengah?</li>
<li>Bagaimana menangani variasi visual yang ekstrim dalam setiap kategori sampah?</li>
<li>Bagaimana memastikan model dapat menggeneralisasi dengan baik pada data baru di lapangan?</li>
</ul>

<h3>1.3 Tujuan Penelitian</h3>
<p>Tujuan utama dari proyek ini adalah:</p>
<ul>
<li>Membangun model CNN dari awal untuk mengklasifikasikan 5 jenis sampah dengan akurasi optimal</li>
<li>Mengimplementasikan teknik preprocessing dan data augmentation yang efektif</li>
<li>Melakukan evaluasi komprehensif terhadap performa model menggunakan berbagai metrik</li>
<li>Memberikan rekomendasi untuk peningkatan dan deployment sistem di lapangan</li>
<li>Menyediakan dokumentasi lengkap untuk keperluan research dan industrialisasi</li>
</ul>

<h2>2. METODOLOGI</h2>

<h3>2.1 Dataset dan Sumber Data</h3>
<p>Dataset yang digunakan berisi gambar sampah dari 5 kategori utama yang sering dijumpai di fasilitas daur ulang:</p>
<ul>
<li><b>Foodwaste (Sampah Makanan/Organik)</b>: Sisa makanan, kulit buah, daun, limbah organik lainnya</li>
<li><b>Glass (Kaca)</b>: Botol kaca, piring kaca, fragmen kaca jernih dan berwarna</li>
<li><b>Metal (Logam)</b>: Kaleng aluminium, kaleng besi, tutup botol, serpihan logam</li>
<li><b>Paper (Kertas)</b>: Kertas, kardus, kemasan kertas, surat</li>
<li><b>Plastic (Plastik)</b>: Botol plastik, kantong plastik, wadah plastik, film plastik</li>
</ul>

<p>Total dataset terdiri dari lebih dari 9,000 gambar yang telah dibagi menjadi tiga subset dengan stratifikasi kelas:</p>
<table>
<tr><th>Subset</th><th>Jumlah Gambar</th><th>Persentase</th><th>Tujuan Penggunaan</th></tr>
<tr><td>Training</td><td>4,116</td><td>49%</td><td>Melatih dan mengupdate parameter model</td></tr>
<tr><td>Validation</td><td>2,520</td><td>30%</td><td>Tuning hyperparameter dan early stopping</td></tr>
<tr><td>Test</td><td>1,186</td><td>21%</td><td>Evaluasi performa final model</td></tr>
</table>

<h3>2.2 Preprocessing Data</h3>
<p>Sebelum input ke model, semua gambar melalui tahap preprocessing yang ketat:</p>
<ul>
<li><b>Resize</b>: Semua gambar diresize menjadi ukuran 64x64 pixels untuk efisiensi komputasi dan memory</li>
<li><b>Normalisasi</b>: Pixel values dinormalisasi ke range [0, 1] dengan membagi dengan 255</li>
<li><b>Color Space Conversion</b>: Konversi dari BGR (OpenCV default) ke RGB untuk konsistensi</li>
<li><b>Stratified Split</b>: Pembagian data menggunakan stratifikasi untuk memastikan distribusi kelas seimbang di setiap subset</li>
</ul>

<h3>2.3 Data Augmentation</h3>
<p>Untuk meningkatkan robustness dan generalisasi model, data augmentation diterapkan pada training set menggunakan ImageDataGenerator:</p>
<ul>
<li>Random Rotation: Rotasi hingga ±20 derajat untuk menangani sampah di berbagai orientasi</li>
<li>Width/Height Shift: Shifting hingga 20% untuk menangani objek di berbagai posisi</li>
<li>Shearing: Shear transformation hingga 20% untuk mensimulasikan perspektif berbeda</li>
<li>Random Zoom: Zoom random hingga 20% untuk mensimulasikan jarak kamera yang bervariasi</li>
<li>Horizontal Flip: Horizontal flipping dengan probabilitas 50%</li>
</ul>

<h3>2.4 Arsitektur Model CNN</h3>
<p>Model CNN yang dikembangkan memiliki arsitektur berlapis sebagai berikut:</p>
<table>
<tr><th>Layer Type</th><th>Konfigurasi</th><th>Output Shape</th><th>Parameters</th></tr>
<tr><td>Input</td><td>RGB Image 64x64</td><td>64×64×3</td><td>0</td></tr>
<tr><td>Conv2D #1</td><td>64 filters, 3×3 kernel, ReLU, Same padding</td><td>64×64×64</td><td>1,792</td></tr>
<tr><td>BatchNormalization #1</td><td>-</td><td>64×64×64</td><td>256</td></tr>
<tr><td>MaxPooling2D #1</td><td>2×2 pool size, stride 2</td><td>32×32×64</td><td>0</td></tr>
<tr><td>Dropout #1</td><td>Rate 0.1</td><td>32×32×64</td><td>0</td></tr>
<tr><td>Conv2D #2</td><td>128 filters, 3×3 kernel, ReLU, Same padding</td><td>32×32×128</td><td>73,856</td></tr>
<tr><td>BatchNormalization #2</td><td>-</td><td>32×32×128</td><td>512</td></tr>
<tr><td>MaxPooling2D #2</td><td>2×2 pool size, stride 2</td><td>16×16×128</td><td>0</td></tr>
<tr><td>Dropout #2</td><td>Rate 0.1</td><td>16×16×128</td><td>0</td></tr>
<tr><td>Conv2D #3</td><td>256 filters, 3×3 kernel, ReLU, Same padding</td><td>16×16×256</td><td>295,168</td></tr>
<tr><td>BatchNormalization #3</td><td>-</td><td>16×16×256</td><td>1,024</td></tr>
<tr><td>MaxPooling2D #3</td><td>2×2 pool size, stride 2</td><td>8×8×256</td><td>0</td></tr>
<tr><td>Dropout #3</td><td>Rate 0.1</td><td>8×8×256</td><td>0</td></tr>
<tr><td>GlobalAveragePooling2D</td><td>-</td><td>256</td><td>0</td></tr>
<tr><td>Dense #1</td><td>256 units, ReLU</td><td>256</td><td>65,792</td></tr>
<tr><td>BatchNormalization #4</td><td>-</td><td>256</td><td>1,024</td></tr>
<tr><td>Dropout #4</td><td>Rate 0.15</td><td>256</td><td>0</td></tr>
<tr><td>Dense #2</td><td>128 units, ReLU</td><td>128</td><td>32,896</td></tr>
<tr><td>BatchNormalization #5</td><td>-</td><td>128</td><td>512</td></tr>
<tr><td>Dropout #5</td><td>Rate 0.15</td><td>128</td><td>0</td></tr>
<tr><td>Output Layer</td><td>5 units, Softmax activation</td><td>5</td><td>645</td></tr>
</table>

<p><b>Total Parameters: 473,477 | Trainable: 471,813 | Non-trainable: 1,664</b></p>
<p><b>Model Size: 1.81 MB</b></p>

<h3>2.5 Hyperparameter dan Konfigurasi Training</h3>
<table>
<tr><th>Hyperparameter</th><th>Nilai</th><th>Penjelasan</th></tr>
<tr><td>Optimizer</td><td>Adam (beta1=0.9, beta2=0.999)</td><td>Adaptive moment estimation untuk learning yang efisien</td></tr>
<tr><td>Learning Rate</td><td>0.0005 (initial), dengan scheduler</td><td>Scheduled: 0.0005 (epoch 0-9), 0.0002 (10-29), 0.0001 (30+)</td></tr>
<tr><td>Loss Function</td><td>Sparse Categorical Crossentropy</td><td>Untuk multi-class classification dengan integer labels</td></tr>
<tr><td>Batch Size</td><td>16</td><td>Balance antara memory efficiency dan gradient stability</td></tr>
<tr><td>Epochs</td><td>100 (max), 53 (actual dengan early stopping)</td><td>Sufficient untuk convergence dengan early stopping protection</td></tr>
<tr><td>Early Stopping Patience</td><td>15 epochs</td><td>Monitor validation loss, tolerant untuk convergence yang lebih smooth</td></tr>
<tr><td>ReduceLROnPlateau</td><td>patience=5, factor=0.5</td><td>Kurangi learning rate 50% jika val_loss plateau</td></tr>
<tr><td>Min Learning Rate</td><td>1e-8</td><td>Mencegah learning rate menjadi terlalu kecil</td></tr>
</table>

<h2>3. HASIL DAN EVALUASI</h2>

<h3>3.1 Performa Model pada Test Set</h3>
<table>
<tr><th>Metrik Performa</th><th>Nilai</th><th>Interpretasi</th></tr>
<tr><td>Overall Accuracy</td><td><b>0.9093 (90.93%)</b></td><td>Proporsi prediksi benar dari total prediksi</td></tr>
<tr><td>Weighted Precision</td><td><b>0.9103</b></td><td>Tingkat akurasi prediksi positif (TP/(TP+FP))</td></tr>
<tr><td>Weighted Recall</td><td><b>0.9093</b></td><td>Tingkat deteksi instance positif (TP/(TP+FN))</td></tr>
<tr><td>F1-Score (Weighted)</td><td><b>0.9092</b></td><td>Harmonic mean dari precision dan recall</td></tr>
<tr><td>Total Test Samples</td><td>1,186 gambar</td><td>Gambar yang tidak pernah dilihat model selama training</td></tr>
</table>

<h3>3.2 Training Progress</h3>
<table>
<tr><th>Metrik Training</th><th>Nilai</th></tr>
<tr><td>Final Training Accuracy</td><td>0.9791</td></tr>
<tr><td>Final Validation Accuracy</td><td>0.8786</td></tr>
<tr><td>Final Training Loss</td><td>0.0705</td></tr>
<tr><td>Final Validation Loss</td><td>0.4541</td></tr>
<tr><td>Epochs Trained</td><td>53</td></tr>
</table>

<h3>3.3 Per-Class Performance</h3>
<p><b>foodwaste</b>: Accuracy 0.9755 (204 samples)</p>
<p><b>glass</b>: Accuracy 0.8400 (200 samples)</p>
<p><b>metal</b>: Accuracy 0.8667 (360 samples)</p>
<p><b>paper</b>: Accuracy 0.9454 (476 samples)</p>
<p><b>plastic</b>: Accuracy 0.9065 (524 samples)</p>

<h3>3.4 Interpretasi Hasil</h3>
<p>Model menunjukkan performa yang sangat baik dengan tingkat akurasi test sebesar 90.93%. Ini menunjukkan bahwa model dapat mengklasifikasikan sampah dengan tingkat keberhasilan yang mengesankan pada data yang belum pernah dilihat sebelumnya. Precision 0.9103 menunjukkan bahwa ketika model memprediksi suatu kategori, tingkat kebenaran relatif tinggi (tingkat false positive rendah). Recall 0.9093 menunjukkan bahwa model dapat mendeteksi mayoritas instance dari setiap kategori dengan baik (tingkat false negative rendah). F1-Score 0.9092 memberikan keseimbangan yang baik antara precision dan recall.</p>

<p>Training progress menunjukkan convergence yang smooth dengan tidak ada indikasi overfitting signifikan. Gap antara training accuracy (0.9791) dan validation accuracy (0.8786) adalah reasonable, menunjukkan model dapat generalisasi dengan baik ke data baru. Learning rate scheduler dan early stopping callbacks membantu mencapai optimal convergence di epoch ke-53.</p>

<h3>3.5 Karakteristik Per Kategori Sampah</h3>
<p>Setiap kategori sampah memiliki karakteristik visual unik dan tantangan tersendiri:</p>

<p><b>Foodwaste (Sampah Makanan/Organik)</b>: Warna dominan coklat/hijau dengan tekstur lembut dan tidak teratur. Tantangan utama adalah variasi sangat tinggi dalam jenis makanan, tingkat dekomposisi yang berbeda, dan kelembaban yang bervariasi. Model harus robust terhadap perubahan warna akibat oksidasi dan deteriorasi.</p>

<p><b>Glass (Kaca)</b>: Warna transparan atau buram dengan reflektansi tinggi. Tantangan spesifik mencakup kesamaan visual dengan plastik bening yang sangat tinggi, pencahayaan background berpengaruh besar pada penampilan, dan transparansi yang dapat menyulitkan ekstraksi fitur tekstur.</p>

<p><b>Metal (Logam)</b>: Warna metalik (silver, copper, bronze) dengan reflektansi sangat tinggi. Tantangan meliputi variasi bentuk dan ukuran yang sangat luas (dari kaleng hingga kepingan kecil), refleksi yang menghasilkan noise pada citra, dan kemampuan reflektansi yang berubah dengan angle cahaya.</p>

<p><b>Paper (Kertas)</b>: Warna dominan putih/cream dengan tekstur datar dan surface matte. Tantangan termasuk kemungkinan confusion dengan cardboard, kertas kusut sulit dibedakan dari kertas rapi, dan beberapa kertas memiliki warna gelap atau berwarna yang kompleks.</p>

<p><b>Plastic (Plastik)</b>: Warna sangat beragam dengan tekstur non-reflektif. Kategori ini PALING SULIT dibedakan dari kategori lain terutama dari glass karena kesamaan warna dan transparansi. Variasi plastik sangat banyak (PET, HDPE, PVC, LDPE) dengan ukuran dan bentuk yang tidak teratur.</p>

<h2>4. PEMBAHASAN DAN ANALISIS</h2>

<h3>4.1 Kekuatan Model yang Dikembangkan</h3>
<p>Model yang dikembangkan memiliki beberapa keunggulan signifikan:</p>
<ul>
<li>Arsitektur yang dioptimalkan dengan 3 convolutional layers + GlobalAveragePooling, efektif untuk klasifikasi 5 kategori</li>
<li>Penggunaan BatchNormalization ekstensif untuk mencegah internal covariate shift dan stabilisasi training</li>
<li>Data augmentation ekstensif meningkatkan robustness model terhadap variasi visual di dunia nyata</li>
<li>Implementation callback (Early Stopping, ReduceLROnPlateau, LearningRateScheduler) mencegah overfitting</li>
<li>Model size terbatas (~1.81 MB) memungkinkan deployment di edge device dengan battery/power terbatas</li>
<li>Inference time cepat (~100-200ms per gambar di CPU), cocok untuk aplikasi real-time</li>
<li>Learning rate scheduler adaptif membantu fine-tuning di fase akhir training</li>
</ul>

<h3>4.2 Keterbatasan dan Tantangan Teridentifikasi</h3>
<p>Beberapa keterbatasan dijumpai selama pengembangan yang penting diketahui:</p>
<ul>
<li>Resolusi gambar 64x64 pixels relatif rendah dan dapat kehilangan detail penting untuk beberapa kategori</li>
<li>Dataset mungkin tidak mencakup semua variasi sampah di dunia nyata (misalnya sampah hazmat, sampah elektronik)</li>
<li>Pencahayaan (lighting), sudut pengambilan (angle), dan background berpengaruh besar pada akurasi prediksi</li>
<li>Sampah yang rusak, tertutup sebagian, atau kabur (blurry) sangat sulit diklasifikasikan dengan akurat</li>
<li>Model tidak robust terhadap distribusi data yang berbeda signifikan dari training data (domain shift)</li>
<li>Kategori yang visually similar (plastic vs glass) masih menjadi challenge utama</li>
</ul>

<h3>4.3 Root Cause Analysis Kesalahan Prediksi</h3>
<p>Confusion matrix analysis menunjukkan bahwa kesalahan utama terjadi antara kategori yang secara visual mirip. Confusion pairs terbesar adalah:</p>
<ul>
<li><b>Glass ↔ Plastic</b>: Keduanya dapat transparan atau semi-transparan dengan reflektansi serupa</li>
<li><b>Metal ↔ Glass</b>: Keduanya memiliki surface reflektif yang tinggi</li>
<li><b>Paper ↔ Plastic</b>: Warna dan tekstur dapat mirip tergantung jenis plastik dan paper</li>
</ul>
<p>Kesalahan ini dapat diminimalkan melalui: (1) training dengan resolusi gambar lebih tinggi (128x128 atau 256x256), (2) data augmentation lebih ekstensif khusus untuk kategori yang sulit, (3) feature extraction lebih dalam dengan network yang lebih besar, (4) ensemble methods menggabungkan multiple models, (5) class-specific data collection dan augmentation strategies.</p>

<h2>5. REKOMENDASI IMPLEMENTASI</h2>

<h3>5.1 Rekomendasi Peningkatan Jangka Pendek (1-3 bulan)</h3>
<ul>
<li>Tingkatkan resolusi input ke 128x128 atau 256x256 dengan GPU yang lebih powerful untuk peningkatan akurasi</li>
<li>Terapkan transfer learning dengan pre-trained models (MobileNet V2, EfficientNet, ResNet50) untuk faster convergence</li>
<li>Implementasikan class weights untuk menangani potential dataset imbalance secara otomatis</li>
<li>Lakukan hyperparameter tuning komprehensif menggunakan Grid Search atau Random Search</li>
<li>Kumpulkan lebih banyak data terutama untuk kategori yang challenging (plastic, glass)</li>
<li>Implementasikan confidence threshold (misalnya 0.70) untuk filtering prediksi yang uncertain</li>
</ul>

<h3>5.2 Rekomendasi Pengembangan Jangka Menengah (3-6 bulan)</h3>
<ul>
<li>Develop model deteksi (YOLO, Faster R-CNN) untuk menangani multiple objects dalam satu gambar</li>
<li>Implementasikan model segmentasi semantic untuk precise boundary detection di conveyor systems</li>
<li>Tambahkan lebih banyak kategori sampah (cardboard, wood, rubber, textile, electronics)</li>
<li>Kumpulkan dataset yang lebih besar dan lebih diverse dari berbagai kondisi real-world</li>
<li>Develop edge version model untuk deployment di IoT/Edge devices dengan quantization dan pruning</li>
<li>Implementasikan active learning untuk smart data collection dari lapangan</li>
</ul>

<h3>5.3 Strategi Deployment dan Monitoring</h3>
<ul>
<li>Deploy model dengan confidence threshold 0.70+ untuk production environment</li>
<li>Implementasi comprehensive logging untuk semua prediksi dan misclassifications</li>
<li>Setup dashboard monitoring untuk track accuracy metrics real-time dari deployed system</li>
<li>Buat feedback loop untuk continuous retraining dengan data baru yang dikumpulkan dari lapangan</li>
<li>Implementasikan A/B testing untuk membandingkan versi model yang berbeda secara bertahap</li>
<li>Setup alert system ketika model accuracy drop di bawah threshold yang ditetapkan</li>
<li>Dokumentasikan semua deployment dan performance metrics untuk audit trail</li>
</ul>

<h2>6. KESIMPULAN</h2>
<p>Penelitian ini berhasil mengembangkan model CNN yang robust dan efisien untuk klasifikasi sampah dengan akurasi test sebesar 90.93%. Model menunjukkan kemampuan yang menjanjikan dalam mengklasifikasikan lima jenis sampah dengan arsitektur yang dioptimalkan dan parameter terbatas (~473K parameters). Implementasi best practices dalam deep learning (data augmentation, batch normalization, callbacks) menghasilkan model yang dapat menggeneralisasi dengan baik ke data baru yang belum pernah dilihat sebelumnya.</p>

<p>Meskipun masih ada ruang untuk peningkatan terutama dalam menangani kategori yang visually similar, hasil ini menunjukkan feasibility menggunakan deep learning untuk aplikasi pemisahan sampah otomatis di dunia nyata. Dengan investasi tambahan dalam mengumpulkan data berkualitas tinggi, meningkatkan resolusi gambar, dan menerapkan teknik advanced seperti transfer learning dan ensemble methods, model ini dapat mencapai performa production-ready (95%+ accuracy).</p>

<p>Implementasi sistem klasifikasi sampah otomatis diharapkan dapat meningkatkan efisiensi daur ulang dari 10% menjadi 40-60%, mengurangi kebutuhan tenaga kerja manual hingga 70%, meningkatkan keselamatan pekerja, dan mengurangi dampak lingkungan dari sampah yang tidak terkelola dengan baik. Proyek ini memberikan foundation yang kuat untuk pengembangan lebih lanjut menuju industrial-grade waste management automation systems.</p>

</div>
</body>
</html>
