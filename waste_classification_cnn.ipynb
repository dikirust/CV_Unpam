{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ef9730",
   "metadata": {},
   "source": [
    "# CNN untuk Klasifikasi Sampah Otomatis\n",
    "\n",
    "**Tugas:** Membangun model CNN dari awal untuk klasifikasi 5 jenis sampah (foodwaste, glass, metal, paper, plastic) untuk sistem pemisah sampah otomatis.\n",
    "\n",
    "**Konfigurasi:** Menggunakan setting ringan untuk laptop dengan spesifikasi rendah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries yang diperlukan untuk CNN, image processing, dan evaluasi model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Setup path untuk dataset, model, dan report\n",
    "BASE_DIR = Path('.')\n",
    "DATASET_DIR = BASE_DIR / 'datasets'\n",
    "MODEL_DIR = BASE_DIR / 'models'\n",
    "REPORT_DIR = BASE_DIR / 'report'\n",
    "\n",
    "# Pastikan folder model dan report ada\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "REPORT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Konfigurasi untuk laptop dengan spec rendah\n",
    "IMG_SIZE = 64  # Ukuran gambar kecil untuk mengurangi memory usage\n",
    "BATCH_SIZE = 16  # Batch size kecil\n",
    "EPOCHS = 10  # Epoch terbatas untuk training cepat\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Class names untuk klasifikasi sampah\n",
    "CLASS_NAMES = ['foodwaste', 'glass', 'metal', 'paper', 'plastic']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Dataset directory: {DATASET_DIR}\")\n",
    "print(f\"Class names: {CLASS_NAMES}\")\n",
    "print(f\"Configuration - Image size: {IMG_SIZE}x{IMG_SIZE}, Batch size: {BATCH_SIZE}, Epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85194fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dan preprocessing dataset dari folder train, valid, test\n",
    "# Normalisasi pixel values ke range 0-1 dan resize gambar ke ukuran kecil\n",
    "\n",
    "def load_dataset(data_dir, img_size=IMG_SIZE):\n",
    "    \"\"\"Load gambar dari folder dan lakukan preprocessing\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "        class_path = data_dir / class_name\n",
    "        if class_path.exists():\n",
    "            print(f\"Loading {class_name} images from {class_path}\")\n",
    "            for img_file in class_path.glob('*.jpg'):\n",
    "                try:\n",
    "                    # Load dan resize gambar\n",
    "                    img = cv2.imread(str(img_file))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (img_size, img_size))\n",
    "                    \n",
    "                    # Normalisasi pixel values ke 0-1\n",
    "                    img = img.astype(np.float32) / 255.0\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    labels.append(class_idx)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_file}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load training, validation, dan test data\n",
    "print(\"Loading training data...\")\n",
    "X_train, y_train = load_dataset(DATASET_DIR / 'train')\n",
    "\n",
    "print(\"Loading validation data...\")\n",
    "X_val, y_val = load_dataset(DATASET_DIR / 'valid')\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "X_test, y_test = load_dataset(DATASET_DIR / 'test')\n",
    "\n",
    "# Print informasi dataset\n",
    "print(f\"\\nDataset Information:\")\n",
    "print(f\"Training set: {X_train.shape} images, {len(np.unique(y_train))} classes\")\n",
    "print(f\"Validation set: {X_val.shape} images, {len(np.unique(y_val))} classes\")\n",
    "print(f\"Test set: {X_test.shape} images, {len(np.unique(y_test))} classes\")\n",
    "print(f\"Image shape: {X_train[0].shape}\")\n",
    "print(f\"Pixel value range: {X_train.min():.2f} - {X_train.max():.2f}\")\n",
    "\n",
    "# Visualisasi sample gambar dari setiap kelas\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i, class_name in enumerate(CLASS_NAMES):\n",
    "    # Ambil sample pertama dari setiap kelas\n",
    "    class_indices = np.where(y_train == i)[0]\n",
    "    if len(class_indices) > 0:\n",
    "        sample_img = X_train[class_indices[0]]\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(sample_img)\n",
    "        plt.title(f\"{class_name}\\n({len(class_indices)} images)\")\n",
    "        plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desain arsitektur CNN sederhana dari awal dengan konfigurasi ringan\n",
    "# Model terdiri dari Conv2D, MaxPooling2D, Flatten, dan Dense layers\n",
    "\n",
    "def create_cnn_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES):\n",
    "    \"\"\"Membuat model CNN sederhana\"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # Layer input\n",
    "        keras.Input(shape=input_shape),\n",
    "        \n",
    "        # Convolutional Layer 1 - filter sedikit untuk mengurangi computational load\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Convolutional Layer 3\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten layer untuk mengubah 2D ke 1D\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Dense layers dengan ukuran kecil\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.3),  # Dropout untuk mencegah overfitting\n",
    "        \n",
    "        # Output layer dengan softmax untuk klasifikasi multi-class\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ], name='WasteClassificationCNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Buat model CNN\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Compile model dengan optimizer Adam dan loss function untuk multi-class classification\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Learning rate standar\n",
    "    loss='sparse_categorical_crossentropy',  # Untuk integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Tampilkan arsitektur model\n",
    "model.summary()\n",
    "\n",
    "# Visualisasi arsitektur model\n",
    "keras.utils.plot_model(\n",
    "    model, \n",
    "    to_file=str(REPORT_DIR / 'model_architecture.png'),\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")\n",
    "\n",
    "print(f\"\\nModel created with {model.count_params():,} total parameters\")\n",
    "print(\"Model architecture saved to report/model_architecture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2eeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model dengan konfigurasi ringan dan callback untuk monitoring\n",
    "# Simpan history training untuk analisis overfitting\n",
    "\n",
    "# Setup callback untuk monitoring training\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "print(f\"Configuration: {EPOCHS} epochs, batch size {BATCH_SIZE}\")\n",
    "\n",
    "# Training model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Plot training history curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(REPORT_DIR / 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Simpan training history\n",
    "with open(MODEL_DIR / 'training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"Training curves saved to report/training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86735c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model pada test set dan hitung semua metrik performa\n",
    "# Generate confusion matrix, classification report, dan export model\n",
    "\n",
    "print(\"Evaluating model on test set...\")\n",
    "\n",
    "# Prediksi pada test set\n",
    "y_pred = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Hitung metrik performa\n",
    "test_accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "test_precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "test_recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "# Classification report detail\n",
    "class_report = classification_report(y_test, y_pred_classes, target_names=CLASS_NAMES, output_dict=True)\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=CLASS_NAMES))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(REPORT_DIR / 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Export model ke format .pkl\n",
    "model_path = MODEL_DIR / 'waste_classification_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Simpan model dalam format .h5 juga untuk kompatibilitas\n",
    "model.save(str(MODEL_DIR / 'waste_classification_model.h5'))\n",
    "\n",
    "print(f\"\\nModel saved to:\")\n",
    "print(f\"- {model_path}\")\n",
    "print(f\"- {MODEL_DIR / 'waste_classification_model.h5'}\")\n",
    "\n",
    "# Generate HTML Report\n",
    "html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Laporan CNN Klasifikasi Sampah</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
    "        h1, h2 {{ color: #2c3e50; }}\n",
    "        .metric {{ background-color: #f8f9fa; padding: 10px; margin: 10px 0; }}\n",
    "        table {{ border-collapse: collapse; width: 100%; }}\n",
    "        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "        th {{ background-color: #f2f2f2; }}\n",
    "        .summary {{ background-color: #e8f4f8; padding: 15px; border-radius: 5px; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Laporan Proyek CNN untuk Klasifikasi Sampah Otomatis</h1>\n",
    "    \n",
    "    <h2>1. Pendahuluan</h2>\n",
    "    <div class=\"summary\">\n",
    "        <h3>Latar Belakang</h3>\n",
    "        <p>Klasifikasi citra merupakan salah satu aplikasi computer vision yang penting dalam kehidupan sehari-hari. \n",
    "        Convolutional Neural Network (CNN) telah terbukti sangat efektif untuk tugas klasifikasi gambar karena \n",
    "        kemampuannya dalam mengenali pola spasial dan fitur visual.</p>\n",
    "        \n",
    "        <h3>Tujuan</h3>\n",
    "        <p>Membangun model CNN dari awal untuk mengklasifikasikan 5 jenis sampah (foodwaste, glass, metal, paper, plastic) \n",
    "        untuk sistem pemisah sampah otomatis.</p>\n",
    "        \n",
    "        <h3>Dataset</h3>\n",
    "        <p>Dataset terdiri dari gambar sampah dengan 5 kategori: foodwaste, glass, metal, paper, dan plastic. \n",
    "        Dataset dibagi menjadi training set ({X_train.shape[0]} gambar), validation set ({X_val.shape[0]} gambar), \n",
    "        dan test set ({X_test.shape[0]} gambar).</p>\n",
    "    </div>\n",
    "    \n",
    "    <h2>2. Metodologi</h2>\n",
    "    <h3>Pra-Pemrosesan</h3>\n",
    "    <p>- Resize gambar ke ukuran {IMG_SIZE}x{IMG_SIZE} pixels untuk efisiensi komputasi</p>\n",
    "    <p>- Normalisasi pixel values ke range 0-1 dengan membagi nilai pixel dengan 255.0</p>\n",
    "    <p>- Konversi color space dari BGR ke RGB</p>\n",
    "    \n",
    "    <h3>Arsitektur Model</h3>\n",
    "    <p>Model CNN sederhana dengan konfigurasi ringan:</p>\n",
    "    <ul>\n",
    "        <li>3 Convolutional layers dengan filter 16, 32, 32</li>\n",
    "        <li>MaxPooling2D setelah setiap conv layer</li>\n",
    "        <li>Flatten layer</li>\n",
    "        <li>Dense layer dengan 32 units + Dropout 0.3</li>\n",
    "        <li>Output layer dengan 5 units (softmax activation)</li>\n",
    "    </ul>\n",
    "    <p>Total parameters: {model.count_params():,}</p>\n",
    "    \n",
    "    <h3>Parameter Pelatihan</h3>\n",
    "    <div class=\"metric\">\n",
    "        <p><strong>Optimizer:</strong> Adam (learning_rate=0.001)</p>\n",
    "        <p><strong>Loss Function:</strong> Sparse Categorical Crossentropy</p>\n",
    "        <p><strong>Batch Size:</strong> {BATCH_SIZE}</p>\n",
    "        <p><strong>Epochs:</strong> {len(history.history['loss'])}</p>\n",
    "        <p><strong>Callbacks:</strong> EarlyStopping, ReduceLROnPlateau</p>\n",
    "    </div>\n",
    "    \n",
    "    <h2>3. Hasil dan Analisis</h2>\n",
    "    <h3>Metrik Performa</h3>\n",
    "    <div class=\"metric\">\n",
    "        <p><strong>Test Accuracy:</strong> {test_accuracy:.4f}</p>\n",
    "        <p><strong>Test Precision:</strong> {test_precision:.4f}</p>\n",
    "        <p><strong>Test Recall:</strong> {test_recall:.4f}</p>\n",
    "        <p><strong>Test F1-Score:</strong> {test_f1:.4f}</p>\n",
    "    </div>\n",
    "    \n",
    "    <h3>Analisis Kinerja</h3>\n",
    "    <h4>Analisis Overfitting</h4>\n",
    "    <p>Berdasarkan training curves, model menunjukkan {'overfitting' if max(history.history['val_accuracy']) < max(history.history['accuracy']) - 0.1 else 'pelatihan yang baik'}. \n",
    "    {'Training accuracy terus naik sementara validation accuracy stagnan, menandakan model terlalu fit pada training data.' if max(history.history['val_accuracy']) < max(history.history['accuracy']) - 0.1 else 'Training dan validation curves relatif seimbang.'}</p>\n",
    "    \n",
    "    <h4>Analisis Kesalahan</h4>\n",
    "    <p>Berdasarkan confusion matrix, kelas yang paling sering salah diklasifikasikan dapat dilihat dari \n",
    "    nilai off-diagonal yang tinggi. Hal ini mungkin disebabkan oleh kesamaan visual antar kategori sampah \n",
    "    tertentu dalam resolusi {IMG_SIZE}x{IMG_SIZE}.</p>\n",
    "    \n",
    "    <h2>4. Kesimpulan</h2>\n",
    "    <div class=\"summary\">\n",
    "        <h3>Temuan Utama</h3>\n",
    "        <p>Model CNN sederhana berhasil mencapai accuracy {test_accuracy:.2%} pada test set. \n",
    "        {'Model mengalami sedikit overfitting' if max(history.history['val_accuracy']) < max(history.history['accuracy']) - 0.1 else 'Model menunjukkan performa yang stabil'}.</p>\n",
    "        \n",
    "        <h3>Saran Perbaikan</h3>\n",
    "        <ol>\n",
    "            <li><strong>Data Augmentation:</strong> Menambahkan rotasi, flip, dan zoom untuk meningkatkan variasi data</li>\n",
    "            <li><strong>Regularization:</strong> Menambahkan dropout lebih banyak atau batch normalization untuk mengurangi overfitting</li>\n",
    "        </ol>\n",
    "    </div>\n",
    "    \n",
    "    <h2>5. Lampiran</h2>\n",
    "    <p>Source code tersedia dalam file: waste_classification_cnn.ipynb</p>\n",
    "    <p>Model tersimpan dalam: models/waste_classification_model.pkl</p>\n",
    "    \n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Simpan HTML report\n",
    "with open(REPORT_DIR / 'waste_classification_report.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"\\\\nReport generated:\")\n",
    "print(f\"- HTML: {REPORT_DIR / 'waste_classification_report.html'}\")\n",
    "print(f\"- Training curves: {REPORT_DIR / 'training_curves.png'}\")\n",
    "print(f\"- Confusion matrix: {REPORT_DIR / 'confusion_matrix.png'}\")\n",
    "print(f\"- Model architecture: {REPORT_DIR / 'model_architecture.png'}\")\n",
    "\n",
    "print(\"\\\\n=== TRAINING COMPLETED ===\")\n",
    "print(\"Files generated:\")\n",
    "print(\"1. Models: models/waste_classification_model.pkl, models/waste_classification_model.h5\")\n",
    "print(\"2. Report: report/waste_classification_report.html\")\n",
    "print(\"3. Visualizations: report/training_curves.png, report/confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
